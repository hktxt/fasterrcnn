{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/jwyang/faster-rcnn.pytorch\n",
    "class _AnchorTargetLayer(nn.Module):\n",
    "    \"\"\"\n",
    "        Assign anchors to ground-truth targets. Produces anchor classification\n",
    "        labels and bounding-box regression targets.\n",
    "    \"\"\"\n",
    "    def __init__(self, feat_stride, scales, ratios):\n",
    "        super(_AnchorTargetLayer, self).__init__()\n",
    "\n",
    "        self._feat_stride = feat_stride\n",
    "        self._scales = scales\n",
    "        anchor_scales = scales\n",
    "        self._anchors = torch.from_numpy(generate_anchors(scales=np.array(anchor_scales), ratios=np.array(ratios))).float()\n",
    "        self._num_anchors = self._anchors.size(0)\n",
    "\n",
    "        # allow boxes to sit over the edge by a small amount\n",
    "        self._allowed_border = 0  # default is 0\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Algorithm:\n",
    "        #\n",
    "        # for each (H, W) location i\n",
    "        #   generate 9 anchor boxes centered on cell i\n",
    "        #   apply predicted bbox deltas at cell i to each of the 9 anchors\n",
    "        # filter out-of-image anchors\n",
    "\n",
    "        rpn_cls_score = input[0]\n",
    "        gt_boxes = input[1]\n",
    "        im_info = input[2]\n",
    "        num_boxes = input[3]\n",
    "\n",
    "        # map of shape (..., H, W)\n",
    "        height, width = rpn_cls_score.size(2), rpn_cls_score.size(3)\n",
    "\n",
    "        batch_size = gt_boxes.size(0)\n",
    "\n",
    "        feat_height, feat_width = rpn_cls_score.size(2), rpn_cls_score.size(3)\n",
    "        shift_x = np.arange(0, feat_width) * self._feat_stride\n",
    "        shift_y = np.arange(0, feat_height) * self._feat_stride\n",
    "        shift_x, shift_y = np.meshgrid(shift_x, shift_y)\n",
    "        shifts = torch.from_numpy(np.vstack((shift_x.ravel(), shift_y.ravel(),\n",
    "                                  shift_x.ravel(), shift_y.ravel())).transpose())\n",
    "        shifts = shifts.contiguous().type_as(rpn_cls_score).float()\n",
    "\n",
    "        A = self._num_anchors\n",
    "        K = shifts.size(0)\n",
    "\n",
    "        self._anchors = self._anchors.type_as(gt_boxes) # move to specific gpu.\n",
    "        all_anchors = self._anchors.view(1, A, 4) + shifts.view(K, 1, 4)\n",
    "        all_anchors = all_anchors.view(K * A, 4)\n",
    "\n",
    "        total_anchors = int(K * A)\n",
    "\n",
    "        keep = ((all_anchors[:, 0] >= -self._allowed_border) &\n",
    "                (all_anchors[:, 1] >= -self._allowed_border) &\n",
    "                (all_anchors[:, 2] < long(im_info[0][1]) + self._allowed_border) &\n",
    "                (all_anchors[:, 3] < long(im_info[0][0]) + self._allowed_border))\n",
    "\n",
    "        inds_inside = torch.nonzero(keep).view(-1)\n",
    "\n",
    "        # keep only inside anchors\n",
    "        anchors = all_anchors[inds_inside, :]\n",
    "\n",
    "        # label: 1 is positive, 0 is negative, -1 is dont care\n",
    "        labels = gt_boxes.new(batch_size, inds_inside.size(0)).fill_(-1)\n",
    "        bbox_inside_weights = gt_boxes.new(batch_size, inds_inside.size(0)).zero_()\n",
    "        bbox_outside_weights = gt_boxes.new(batch_size, inds_inside.size(0)).zero_()\n",
    "\n",
    "        overlaps = bbox_overlaps_batch(anchors, gt_boxes)\n",
    "\n",
    "        max_overlaps, argmax_overlaps = torch.max(overlaps, 2)\n",
    "        gt_max_overlaps, _ = torch.max(overlaps, 1)\n",
    "\n",
    "        if not cfg.TRAIN.RPN_CLOBBER_POSITIVES:\n",
    "            labels[max_overlaps < cfg.TRAIN.RPN_NEGATIVE_OVERLAP] = 0\n",
    "\n",
    "        gt_max_overlaps[gt_max_overlaps==0] = 1e-5\n",
    "        keep = torch.sum(overlaps.eq(gt_max_overlaps.view(batch_size,1,-1).expand_as(overlaps)), 2)\n",
    "\n",
    "        if torch.sum(keep) > 0:\n",
    "            labels[keep>0] = 1\n",
    "\n",
    "        # fg label: above threshold IOU\n",
    "        labels[max_overlaps >= cfg.TRAIN.RPN_POSITIVE_OVERLAP] = 1\n",
    "\n",
    "        if cfg.TRAIN.RPN_CLOBBER_POSITIVES:\n",
    "            labels[max_overlaps < cfg.TRAIN.RPN_NEGATIVE_OVERLAP] = 0\n",
    "\n",
    "        num_fg = int(cfg.TRAIN.RPN_FG_FRACTION * cfg.TRAIN.RPN_BATCHSIZE)\n",
    "\n",
    "        sum_fg = torch.sum((labels == 1).int(), 1)\n",
    "        sum_bg = torch.sum((labels == 0).int(), 1)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            # subsample positive labels if we have too many\n",
    "            if sum_fg[i] > num_fg:\n",
    "                fg_inds = torch.nonzero(labels[i] == 1).view(-1)\n",
    "                # torch.randperm seems has a bug on multi-gpu setting that cause the segfault.\n",
    "                # See https://github.com/pytorch/pytorch/issues/1868 for more details.\n",
    "                # use numpy instead.\n",
    "                #rand_num = torch.randperm(fg_inds.size(0)).type_as(gt_boxes).long()\n",
    "                rand_num = torch.from_numpy(np.random.permutation(fg_inds.size(0))).type_as(gt_boxes).long()\n",
    "                disable_inds = fg_inds[rand_num[:fg_inds.size(0)-num_fg]]\n",
    "                labels[i][disable_inds] = -1\n",
    "\n",
    "#           num_bg = cfg.TRAIN.RPN_BATCHSIZE - sum_fg[i]\n",
    "            num_bg = cfg.TRAIN.RPN_BATCHSIZE - torch.sum((labels == 1).int(), 1)[i]\n",
    "\n",
    "            # subsample negative labels if we have too many\n",
    "            if sum_bg[i] > num_bg:\n",
    "                bg_inds = torch.nonzero(labels[i] == 0).view(-1)\n",
    "                #rand_num = torch.randperm(bg_inds.size(0)).type_as(gt_boxes).long()\n",
    "\n",
    "                rand_num = torch.from_numpy(np.random.permutation(bg_inds.size(0))).type_as(gt_boxes).long()\n",
    "                disable_inds = bg_inds[rand_num[:bg_inds.size(0)-num_bg]]\n",
    "                labels[i][disable_inds] = -1\n",
    "\n",
    "        offset = torch.arange(0, batch_size)*gt_boxes.size(1)\n",
    "\n",
    "        argmax_overlaps = argmax_overlaps + offset.view(batch_size, 1).type_as(argmax_overlaps)\n",
    "        bbox_targets = _compute_targets_batch(anchors, gt_boxes.view(-1,5)[argmax_overlaps.view(-1), :].view(batch_size, -1, 5))\n",
    "\n",
    "        # use a single value instead of 4 values for easy index.\n",
    "        bbox_inside_weights[labels==1] = cfg.TRAIN.RPN_BBOX_INSIDE_WEIGHTS[0]\n",
    "\n",
    "        if cfg.TRAIN.RPN_POSITIVE_WEIGHT < 0:\n",
    "            num_examples = torch.sum(labels[i] >= 0)\n",
    "            positive_weights = 1.0 / num_examples.item()\n",
    "            negative_weights = 1.0 / num_examples.item()\n",
    "        else:\n",
    "            assert ((cfg.TRAIN.RPN_POSITIVE_WEIGHT > 0) &\n",
    "                    (cfg.TRAIN.RPN_POSITIVE_WEIGHT < 1))\n",
    "\n",
    "        bbox_outside_weights[labels == 1] = positive_weights\n",
    "        bbox_outside_weights[labels == 0] = negative_weights\n",
    "\n",
    "        labels = _unmap(labels, total_anchors, inds_inside, batch_size, fill=-1)\n",
    "        bbox_targets = _unmap(bbox_targets, total_anchors, inds_inside, batch_size, fill=0)\n",
    "        bbox_inside_weights = _unmap(bbox_inside_weights, total_anchors, inds_inside, batch_size, fill=0)\n",
    "        bbox_outside_weights = _unmap(bbox_outside_weights, total_anchors, inds_inside, batch_size, fill=0)\n",
    "\n",
    "        outputs = []\n",
    "\n",
    "        labels = labels.view(batch_size, height, width, A).permute(0,3,1,2).contiguous()\n",
    "        labels = labels.view(batch_size, 1, A * height, width)\n",
    "        outputs.append(labels)\n",
    "\n",
    "        bbox_targets = bbox_targets.view(batch_size, height, width, A*4).permute(0,3,1,2).contiguous()\n",
    "        outputs.append(bbox_targets)\n",
    "\n",
    "        anchors_count = bbox_inside_weights.size(1)\n",
    "        bbox_inside_weights = bbox_inside_weights.view(batch_size,anchors_count,1).expand(batch_size, anchors_count, 4)\n",
    "\n",
    "        bbox_inside_weights = bbox_inside_weights.contiguous().view(batch_size, height, width, 4*A)\\\n",
    "                            .permute(0,3,1,2).contiguous()\n",
    "\n",
    "        outputs.append(bbox_inside_weights)\n",
    "\n",
    "        bbox_outside_weights = bbox_outside_weights.view(batch_size,anchors_count,1).expand(batch_size, anchors_count, 4)\n",
    "        bbox_outside_weights = bbox_outside_weights.contiguous().view(batch_size, height, width, 4*A)\\\n",
    "                            .permute(0,3,1,2).contiguous()\n",
    "        outputs.append(bbox_outside_weights)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def backward(self, top, propagate_down, bottom):\n",
    "        \"\"\"This layer does not propagate gradients.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def reshape(self, bottom, top):\n",
    "        \"\"\"Reshaping happens during the call to forward.\"\"\"\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
