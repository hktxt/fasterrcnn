{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-baa5412d2743>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# %load trainval_net.py\n",
    "# --------------------------------------------------------\n",
    "# Pytorch multi-GPU Faster R-CNN\n",
    "# Licensed under The MIT License [see LICENSE for details]\n",
    "# Written by Jiasen Lu, Jianwei Yang, based on code from Ross Girshick\n",
    "# --------------------------------------------------------\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import _init_paths\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pprint\n",
    "import pdb\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import Sampler\n",
    "\n",
    "from roi_data_layer.roidb import combined_roidb\n",
    "from roi_data_layer.roibatchLoader import roibatchLoader\n",
    "from model.utils.config import cfg, cfg_from_file, cfg_from_list, get_output_dir\n",
    "from model.utils.net_utils import weights_normal_init, save_net, load_net, \\\n",
    "      adjust_learning_rate, save_checkpoint, clip_gradient\n",
    "\n",
    "from model.faster_rcnn.vgg16 import vgg16\n",
    "from model.faster_rcnn.resnet import resnet\n",
    "\n",
    "def parse_args():\n",
    "  \"\"\"\n",
    "  Parse input arguments\n",
    "  \"\"\"\n",
    "  parser = argparse.ArgumentParser(description='Train a Fast R-CNN network')\n",
    "  parser.add_argument('--dataset', dest='dataset',\n",
    "                      help='training dataset',\n",
    "                      default='pascal_voc', type=str)\n",
    "  parser.add_argument('--net', dest='net',\n",
    "                    help='vgg16, res101',\n",
    "                    default='vgg16', type=str)\n",
    "  parser.add_argument('--start_epoch', dest='start_epoch',\n",
    "                      help='starting epoch',\n",
    "                      default=1, type=int)\n",
    "  parser.add_argument('--epochs', dest='max_epochs',\n",
    "                      help='number of epochs to train',\n",
    "                      default=20, type=int)\n",
    "  parser.add_argument('--disp_interval', dest='disp_interval',\n",
    "                      help='number of iterations to display',\n",
    "                      default=100, type=int)\n",
    "  parser.add_argument('--checkpoint_interval', dest='checkpoint_interval',\n",
    "                      help='number of iterations to display',\n",
    "                      default=10000, type=int)\n",
    "\n",
    "  parser.add_argument('--save_dir', dest='save_dir',\n",
    "                      help='directory to save models', default=\"models\",\n",
    "                      type=str)\n",
    "  parser.add_argument('--nw', dest='num_workers',\n",
    "                      help='number of worker to load data',\n",
    "                      default=0, type=int)\n",
    "  parser.add_argument('--cuda', dest='cuda',\n",
    "                      help='whether use CUDA',\n",
    "                      action='store_true')\n",
    "  parser.add_argument('--ls', dest='large_scale',\n",
    "                      help='whether use large imag scale',\n",
    "                      action='store_true')                      \n",
    "  parser.add_argument('--mGPUs', dest='mGPUs',\n",
    "                      help='whether use multiple GPUs',\n",
    "                      action='store_true')\n",
    "  parser.add_argument('--bs', dest='batch_size',\n",
    "                      help='batch_size',\n",
    "                      default=1, type=int)\n",
    "  parser.add_argument('--cag', dest='class_agnostic',\n",
    "                      help='whether perform class_agnostic bbox regression',\n",
    "                      action='store_true')\n",
    "\n",
    "# config optimization\n",
    "  parser.add_argument('--o', dest='optimizer',\n",
    "                      help='training optimizer',\n",
    "                      default=\"sgd\", type=str)\n",
    "  parser.add_argument('--lr', dest='lr',\n",
    "                      help='starting learning rate',\n",
    "                      default=0.001, type=float)\n",
    "  parser.add_argument('--lr_decay_step', dest='lr_decay_step',\n",
    "                      help='step to do learning rate decay, unit is epoch',\n",
    "                      default=5, type=int)\n",
    "  parser.add_argument('--lr_decay_gamma', dest='lr_decay_gamma',\n",
    "                      help='learning rate decay ratio',\n",
    "                      default=0.1, type=float)\n",
    "\n",
    "# set training session\n",
    "  parser.add_argument('--s', dest='session',\n",
    "                      help='training session',\n",
    "                      default=1, type=int)\n",
    "\n",
    "# resume trained model\n",
    "  parser.add_argument('--r', dest='resume',\n",
    "                      help='resume checkpoint or not',\n",
    "                      default=False, type=bool)\n",
    "  parser.add_argument('--checksession', dest='checksession',\n",
    "                      help='checksession to load model',\n",
    "                      default=1, type=int)\n",
    "  parser.add_argument('--checkepoch', dest='checkepoch',\n",
    "                      help='checkepoch to load model',\n",
    "                      default=1, type=int)\n",
    "  parser.add_argument('--checkpoint', dest='checkpoint',\n",
    "                      help='checkpoint to load model',\n",
    "                      default=0, type=int)\n",
    "# log and diaplay\n",
    "  parser.add_argument('--use_tfb', dest='use_tfboard',\n",
    "                      help='whether use tensorboard',\n",
    "                      action='store_true')\n",
    "\n",
    "  args = parser.parse_args()\n",
    "  return args\n",
    "\n",
    "\n",
    "class sampler(Sampler):\n",
    "  def __init__(self, train_size, batch_size):\n",
    "    self.num_data = train_size\n",
    "    self.num_per_batch = int(train_size / batch_size)\n",
    "    self.batch_size = batch_size\n",
    "    self.range = torch.arange(0,batch_size).view(1, batch_size).long()\n",
    "    self.leftover_flag = False\n",
    "    if train_size % batch_size:\n",
    "      self.leftover = torch.arange(self.num_per_batch*batch_size, train_size).long()\n",
    "      self.leftover_flag = True\n",
    "\n",
    "  def __iter__(self):\n",
    "    rand_num = torch.randperm(self.num_per_batch).view(-1,1) * self.batch_size\n",
    "    self.rand_num = rand_num.expand(self.num_per_batch, self.batch_size) + self.range\n",
    "\n",
    "    self.rand_num_view = self.rand_num.view(-1)\n",
    "\n",
    "    if self.leftover_flag:\n",
    "      self.rand_num_view = torch.cat((self.rand_num_view, self.leftover),0)\n",
    "\n",
    "    return iter(self.rand_num_view)\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.num_data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "  args = parse_args()\n",
    "\n",
    "  print('Called with args:')\n",
    "  print(args)\n",
    "\n",
    "  if args.dataset == \"pascal_voc\":\n",
    "      args.imdb_name = \"voc_2007_trainval\"\n",
    "      args.imdbval_name = \"voc_2007_test\"\n",
    "      args.set_cfgs = ['ANCHOR_SCALES', '[8, 16, 32]', 'ANCHOR_RATIOS', '[0.5,1,2]', 'MAX_NUM_GT_BOXES', '20']\n",
    "  elif args.dataset == \"pascal_voc_0712\":\n",
    "      args.imdb_name = \"voc_2007_trainval+voc_2012_trainval\"\n",
    "      args.imdbval_name = \"voc_2007_test\"\n",
    "      args.set_cfgs = ['ANCHOR_SCALES', '[8, 16, 32]', 'ANCHOR_RATIOS', '[0.5,1,2]', 'MAX_NUM_GT_BOXES', '20']\n",
    "  elif args.dataset == \"coco\":\n",
    "      args.imdb_name = \"coco_2014_train+coco_2014_valminusminival\"\n",
    "      args.imdbval_name = \"coco_2014_minival\"\n",
    "      args.set_cfgs = ['ANCHOR_SCALES', '[4, 8, 16, 32]', 'ANCHOR_RATIOS', '[0.5,1,2]', 'MAX_NUM_GT_BOXES', '50']\n",
    "  elif args.dataset == \"imagenet\":\n",
    "      args.imdb_name = \"imagenet_train\"\n",
    "      args.imdbval_name = \"imagenet_val\"\n",
    "      args.set_cfgs = ['ANCHOR_SCALES', '[4, 8, 16, 32]', 'ANCHOR_RATIOS', '[0.5,1,2]', 'MAX_NUM_GT_BOXES', '30']\n",
    "  elif args.dataset == \"vg\":\n",
    "      # train sizes: train, smalltrain, minitrain\n",
    "      # train scale: ['150-50-20', '150-50-50', '500-150-80', '750-250-150', '1750-700-450', '1600-400-20']\n",
    "      args.imdb_name = \"vg_150-50-50_minitrain\"\n",
    "      args.imdbval_name = \"vg_150-50-50_minival\"\n",
    "      args.set_cfgs = ['ANCHOR_SCALES', '[4, 8, 16, 32]', 'ANCHOR_RATIOS', '[0.5,1,2]', 'MAX_NUM_GT_BOXES', '50']\n",
    "\n",
    "  args.cfg_file = \"cfgs/{}_ls.yml\".format(args.net) if args.large_scale else \"cfgs/{}.yml\".format(args.net)\n",
    "\n",
    "  if args.cfg_file is not None:\n",
    "    cfg_from_file(args.cfg_file)\n",
    "  if args.set_cfgs is not None:\n",
    "    cfg_from_list(args.set_cfgs)\n",
    "\n",
    "  print('Using config:')\n",
    "  pprint.pprint(cfg)\n",
    "  np.random.seed(cfg.RNG_SEED)\n",
    "\n",
    "  #torch.backends.cudnn.benchmark = True\n",
    "  if torch.cuda.is_available() and not args.cuda:\n",
    "    print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
    "\n",
    "  # train set\n",
    "  # -- Note: Use validation set and disable the flipped to enable faster loading.\n",
    "  cfg.TRAIN.USE_FLIPPED = True\n",
    "  cfg.USE_GPU_NMS = args.cuda\n",
    "  imdb, roidb, ratio_list, ratio_index = combined_roidb(args.imdb_name)\n",
    "  train_size = len(roidb)\n",
    "\n",
    "  print('{:d} roidb entries'.format(len(roidb)))\n",
    "\n",
    "  output_dir = args.save_dir + \"/\" + args.net + \"/\" + args.dataset\n",
    "  if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "  sampler_batch = sampler(train_size, args.batch_size)\n",
    "\n",
    "  dataset = roibatchLoader(roidb, ratio_list, ratio_index, args.batch_size, \\\n",
    "                           imdb.num_classes, training=True)\n",
    "\n",
    "  dataloader = torch.utils.data.DataLoader(dataset, batch_size=args.batch_size,\n",
    "                            sampler=sampler_batch, num_workers=args.num_workers)\n",
    "\n",
    "  # initilize the tensor holder here.\n",
    "  im_data = torch.FloatTensor(1)\n",
    "  im_info = torch.FloatTensor(1)\n",
    "  num_boxes = torch.LongTensor(1)\n",
    "  gt_boxes = torch.FloatTensor(1)\n",
    "\n",
    "  # ship to cuda\n",
    "  if args.cuda:\n",
    "    im_data = im_data.cuda()\n",
    "    im_info = im_info.cuda()\n",
    "    num_boxes = num_boxes.cuda()\n",
    "    gt_boxes = gt_boxes.cuda()\n",
    "\n",
    "  # make variable\n",
    "  im_data = Variable(im_data)\n",
    "  im_info = Variable(im_info)\n",
    "  num_boxes = Variable(num_boxes)\n",
    "  gt_boxes = Variable(gt_boxes)\n",
    "\n",
    "  if args.cuda:\n",
    "    cfg.CUDA = True\n",
    "\n",
    "  # initilize the network here.\n",
    "  if args.net == 'vgg16':\n",
    "    fasterRCNN = vgg16(imdb.classes, pretrained=True, class_agnostic=args.class_agnostic)\n",
    "  elif args.net == 'res101':\n",
    "    fasterRCNN = resnet(imdb.classes, 101, pretrained=True, class_agnostic=args.class_agnostic)\n",
    "  elif args.net == 'res50':\n",
    "    fasterRCNN = resnet(imdb.classes, 50, pretrained=True, class_agnostic=args.class_agnostic)\n",
    "  elif args.net == 'res152':\n",
    "    fasterRCNN = resnet(imdb.classes, 152, pretrained=True, class_agnostic=args.class_agnostic)\n",
    "  else:\n",
    "    print(\"network is not defined\")\n",
    "    pdb.set_trace()\n",
    "\n",
    "  fasterRCNN.create_architecture()\n",
    "\n",
    "  lr = cfg.TRAIN.LEARNING_RATE\n",
    "  lr = args.lr\n",
    "  #tr_momentum = cfg.TRAIN.MOMENTUM\n",
    "  #tr_momentum = args.momentum\n",
    "\n",
    "  params = []\n",
    "  for key, value in dict(fasterRCNN.named_parameters()).items():\n",
    "    if value.requires_grad:\n",
    "      if 'bias' in key:\n",
    "        params += [{'params':[value],'lr':lr*(cfg.TRAIN.DOUBLE_BIAS + 1), \\\n",
    "                'weight_decay': cfg.TRAIN.BIAS_DECAY and cfg.TRAIN.WEIGHT_DECAY or 0}]\n",
    "      else:\n",
    "        params += [{'params':[value],'lr':lr, 'weight_decay': cfg.TRAIN.WEIGHT_DECAY}]\n",
    "\n",
    "  if args.cuda:\n",
    "    fasterRCNN.cuda()\n",
    "      \n",
    "  if args.optimizer == \"adam\":\n",
    "    lr = lr * 0.1\n",
    "    optimizer = torch.optim.Adam(params)\n",
    "\n",
    "  elif args.optimizer == \"sgd\":\n",
    "    optimizer = torch.optim.SGD(params, momentum=cfg.TRAIN.MOMENTUM)\n",
    "\n",
    "  if args.resume:\n",
    "    load_name = os.path.join(output_dir,\n",
    "      'faster_rcnn_{}_{}_{}.pth'.format(args.checksession, args.checkepoch, args.checkpoint))\n",
    "    print(\"loading checkpoint %s\" % (load_name))\n",
    "    checkpoint = torch.load(load_name)\n",
    "    args.session = checkpoint['session']\n",
    "    args.start_epoch = checkpoint['epoch']\n",
    "    fasterRCNN.load_state_dict(checkpoint['model'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    if 'pooling_mode' in checkpoint.keys():\n",
    "      cfg.POOLING_MODE = checkpoint['pooling_mode']\n",
    "    print(\"loaded checkpoint %s\" % (load_name))\n",
    "\n",
    "  if args.mGPUs:\n",
    "    fasterRCNN = nn.DataParallel(fasterRCNN)\n",
    "\n",
    "  iters_per_epoch = int(train_size / args.batch_size)\n",
    "\n",
    "  if args.use_tfboard:\n",
    "    from tensorboardX import SummaryWriter\n",
    "    logger = SummaryWriter(\"logs\")\n",
    "\n",
    "  for epoch in range(args.start_epoch, args.max_epochs + 1):\n",
    "    # setting to train mode\n",
    "    fasterRCNN.train()\n",
    "    loss_temp = 0\n",
    "    start = time.time()\n",
    "\n",
    "    if epoch % (args.lr_decay_step + 1) == 0:\n",
    "        adjust_learning_rate(optimizer, args.lr_decay_gamma)\n",
    "        lr *= args.lr_decay_gamma\n",
    "\n",
    "    data_iter = iter(dataloader)\n",
    "    for step in range(iters_per_epoch):\n",
    "      data = next(data_iter)\n",
    "      im_data.data.resize_(data[0].size()).copy_(data[0])\n",
    "      im_info.data.resize_(data[1].size()).copy_(data[1])\n",
    "      gt_boxes.data.resize_(data[2].size()).copy_(data[2])\n",
    "      num_boxes.data.resize_(data[3].size()).copy_(data[3])\n",
    "\n",
    "      fasterRCNN.zero_grad()\n",
    "      rois, cls_prob, bbox_pred, \\\n",
    "      rpn_loss_cls, rpn_loss_box, \\\n",
    "      RCNN_loss_cls, RCNN_loss_bbox, \\\n",
    "      rois_label = fasterRCNN(im_data, im_info, gt_boxes, num_boxes)\n",
    "\n",
    "      loss = rpn_loss_cls.mean() + rpn_loss_box.mean() \\\n",
    "           + RCNN_loss_cls.mean() + RCNN_loss_bbox.mean()\n",
    "      loss_temp += loss.item()\n",
    "\n",
    "      # backward\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      if args.net == \"vgg16\":\n",
    "          clip_gradient(fasterRCNN, 10.)\n",
    "      optimizer.step()\n",
    "\n",
    "      if step % args.disp_interval == 0:\n",
    "        end = time.time()\n",
    "        if step > 0:\n",
    "          loss_temp /= (args.disp_interval + 1)\n",
    "\n",
    "        if args.mGPUs:\n",
    "          loss_rpn_cls = rpn_loss_cls.mean().item()\n",
    "          loss_rpn_box = rpn_loss_box.mean().item()\n",
    "          loss_rcnn_cls = RCNN_loss_cls.mean().item()\n",
    "          loss_rcnn_box = RCNN_loss_bbox.mean().item()\n",
    "          fg_cnt = torch.sum(rois_label.data.ne(0))\n",
    "          bg_cnt = rois_label.data.numel() - fg_cnt\n",
    "        else:\n",
    "          loss_rpn_cls = rpn_loss_cls.item()\n",
    "          loss_rpn_box = rpn_loss_box.item()\n",
    "          loss_rcnn_cls = RCNN_loss_cls.item()\n",
    "          loss_rcnn_box = RCNN_loss_bbox.item()\n",
    "          fg_cnt = torch.sum(rois_label.data.ne(0))\n",
    "          bg_cnt = rois_label.data.numel() - fg_cnt\n",
    "\n",
    "        print(\"[session %d][epoch %2d][iter %4d/%4d] loss: %.4f, lr: %.2e\" \\\n",
    "                                % (args.session, epoch, step, iters_per_epoch, loss_temp, lr))\n",
    "        print(\"\\t\\t\\tfg/bg=(%d/%d), time cost: %f\" % (fg_cnt, bg_cnt, end-start))\n",
    "        print(\"\\t\\t\\trpn_cls: %.4f, rpn_box: %.4f, rcnn_cls: %.4f, rcnn_box %.4f\" \\\n",
    "                      % (loss_rpn_cls, loss_rpn_box, loss_rcnn_cls, loss_rcnn_box))\n",
    "        if args.use_tfboard:\n",
    "          info = {\n",
    "            'loss': loss_temp,\n",
    "            'loss_rpn_cls': loss_rpn_cls,\n",
    "            'loss_rpn_box': loss_rpn_box,\n",
    "            'loss_rcnn_cls': loss_rcnn_cls,\n",
    "            'loss_rcnn_box': loss_rcnn_box\n",
    "          }\n",
    "          logger.add_scalars(\"logs_s_{}/losses\".format(args.session), info, (epoch - 1) * iters_per_epoch + step)\n",
    "\n",
    "        loss_temp = 0\n",
    "        start = time.time()\n",
    "\n",
    "    \n",
    "    save_name = os.path.join(output_dir, 'faster_rcnn_{}_{}_{}.pth'.format(args.session, epoch, step))\n",
    "    save_checkpoint({\n",
    "      'session': args.session,\n",
    "      'epoch': epoch + 1,\n",
    "      'model': fasterRCNN.module.state_dict() if args.mGPUs else fasterRCNN.state_dict(),\n",
    "      'optimizer': optimizer.state_dict(),\n",
    "      'pooling_mode': cfg.POOLING_MODE,\n",
    "      'class_agnostic': args.class_agnostic,\n",
    "    }, save_name)\n",
    "    print('save model: {}'.format(save_name))\n",
    "\n",
    "  if args.use_tfboard:\n",
    "    logger.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-eb42ca6e4af3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
