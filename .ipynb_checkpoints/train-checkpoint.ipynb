{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/@fractaldle/guide-to-build-faster-rcnn-in-pytorch-95b10c273439\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from utils import torch_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using 1 GPU...\n",
      "1/1:_CudaDeviceProperties(name='GeForce RTX 2070', major=7, minor=5, total_memory=8192MB, multi_processor_count=36)\n"
     ]
    }
   ],
   "source": [
    "# specify visible GPUs\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "device = torch_utils.select_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cfgs/vgg16.yml'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = 'vgg16'\n",
    "cfg_file = 'cfgs/{}.yml'.format(net);cfg_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "image = torch.zeros((1, 3, 800, 800)).float()\n",
    "\n",
    "bbox = torch.FloatTensor([[20, 30, 400, 500], [300, 400, 500, 600]]) # [y1, x1, y2, x2] format\n",
    "labels = torch.LongTensor([6, 8]) # 0 represents background\n",
    "sub_sample = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "dummy_img = torch.zeros((1, 3, 800, 800)).float()\n",
    "print(dummy_img)\n",
    "#Out: torch.Size([1, 3, 800, 800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\hktxt/.torch\\models\\vgg16-397923af.pth\n",
      "100%|██████████| 553433881/553433881 [00:22<00:00, 24947367.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)]\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.vgg16(pretrained=True)\n",
    "fe = list(model.features)\n",
    "print(fe) # length is 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "req_features = []\n",
    "k = dummy_img.clone()\n",
    "for i in fe:\n",
    "    k = i(k)\n",
    "    if k.size()[2] < 800//16:\n",
    "        break\n",
    "    req_features.append(i)\n",
    "    out_channels = k.size()[1]\n",
    "print(len(req_features)) #30\n",
    "print(out_channels) # 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "faster_rcnn_fe_extractor = nn.Sequential(*req_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 50, 50])\n"
     ]
    }
   ],
   "source": [
    "out_map = faster_rcnn_fe_extractor(image)\n",
    "print(out_map.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "ratios = [0.5, 1, 2]\n",
    "anchor_scales = [8, 16, 32]\n",
    "\n",
    "anchor_base = np.zeros((len(ratios) * len(anchor_scales), 4), dtype=np.float32)\n",
    "\n",
    "print(anchor_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0 8.0\n"
     ]
    }
   ],
   "source": [
    "sub_sample = 16\n",
    "ctr_y = sub_sample / 2.\n",
    "ctr_x = sub_sample / 2.\n",
    "\n",
    "print(ctr_y, ctr_x)\n",
    "# Out: (8, 8)\n",
    "for i in range(len(ratios)):\n",
    "    for j in range(len(anchor_scales)):\n",
    "        h = sub_sample * anchor_scales[j] * np.sqrt(ratios[i])\n",
    "        w = sub_sample * anchor_scales[j] * np.sqrt(1./ ratios[i])\n",
    "\n",
    "        index = i * len(anchor_scales) + j\n",
    "\n",
    "        anchor_base[index, 0] = ctr_y - h / 2.\n",
    "        anchor_base[index, 1] = ctr_x - w / 2.\n",
    "        anchor_base[index, 2] = ctr_y + h / 2.\n",
    "        anchor_base[index, 3] = ctr_x + w / 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -37.254833,  -82.50967 ,   53.254833,   98.50967 ],\n",
       "       [ -82.50967 , -173.01933 ,   98.50967 ,  189.01933 ],\n",
       "       [-173.01933 , -354.03867 ,  189.01933 ,  370.03867 ],\n",
       "       [ -56.      ,  -56.      ,   72.      ,   72.      ],\n",
       "       [-120.      , -120.      ,  136.      ,  136.      ],\n",
       "       [-248.      , -248.      ,  264.      ,  264.      ],\n",
       "       [ -82.50967 ,  -37.254833,   98.50967 ,   53.254833],\n",
       "       [-173.01933 ,  -82.50967 ,  189.01933 ,   98.50967 ],\n",
       "       [-354.03867 , -173.01933 ,  370.03867 ,  189.01933 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# https://github.com/rbgirshick/py-faster-rcnn/blob/master/lib/rpn/generate_anchors.py\n",
    "# Verify that we compute the same anchors as Shaoqing's matlab implementation:\n",
    "#\n",
    "#    >> load output/rpn_cachedir/faster_rcnn_VOC2007_ZF_stage1_rpn/anchors.mat\n",
    "#    >> anchors\n",
    "#\n",
    "#    anchors =\n",
    "#\n",
    "#       -83   -39   100    56\n",
    "#      -175   -87   192   104\n",
    "#      -359  -183   376   200\n",
    "#       -55   -55    72    72\n",
    "#      -119  -119   136   136\n",
    "#      -247  -247   264   264\n",
    "#       -35   -79    52    96\n",
    "#       -79  -167    96   184\n",
    "#      -167  -343   184   360\n",
    "\n",
    "#array([[ -83.,  -39.,  100.,   56.],\n",
    "#       [-175.,  -87.,  192.,  104.],\n",
    "#       [-359., -183.,  376.,  200.],\n",
    "#       [ -55.,  -55.,   72.,   72.],\n",
    "#       [-119., -119.,  136.,  136.],\n",
    "#       [-247., -247.,  264.,  264.],\n",
    "#       [ -35.,  -79.,   52.,   96.],\n",
    "#       [ -79., -167.,   96.,  184.],\n",
    "#       [-167., -343.,  184.,  360.]])\n",
    "\n",
    "def generate_anchors(base_size=16, ratios=[0.5, 1, 2],\n",
    "                     scales=2**np.arange(3, 6)):\n",
    "    \"\"\"\n",
    "    Generate anchor (reference) windows by enumerating aspect ratios X\n",
    "    scales wrt a reference (0, 0, 15, 15) window.\n",
    "    \"\"\"\n",
    "\n",
    "    base_anchor = np.array([1, 1, base_size, base_size]) - 1 # [ 0  0 15 15]\n",
    "    #print(base_anchor)\n",
    "    ratio_anchors = _ratio_enum(base_anchor, ratios)\n",
    "    anchors = np.vstack([_scale_enum(ratio_anchors[i, :], scales)\n",
    "                         for i in range(ratio_anchors.shape[0])])\n",
    "    return anchors\n",
    "\n",
    "def _whctrs(anchor):\n",
    "    \"\"\"\n",
    "    Return width, height, x center, and y center for an anchor (window).\n",
    "    \"\"\"\n",
    "\n",
    "    w = anchor[2] - anchor[0] + 1\n",
    "    h = anchor[3] - anchor[1] + 1\n",
    "    x_ctr = anchor[0] + 0.5 * (w - 1)\n",
    "    y_ctr = anchor[1] + 0.5 * (h - 1)\n",
    "    return w, h, x_ctr, y_ctr # 16 16 7.5 7.5\n",
    "\n",
    "def _mkanchors(ws, hs, x_ctr, y_ctr):\n",
    "    \"\"\"\n",
    "    Given a vector of widths (ws) and heights (hs) around a center\n",
    "    (x_ctr, y_ctr), output a set of anchors (windows).\n",
    "    \"\"\"\n",
    "\n",
    "    ws = ws[:, np.newaxis] # \n",
    "    hs = hs[:, np.newaxis] #\n",
    "    anchors = np.hstack((x_ctr - 0.5 * (ws - 1),\n",
    "                         y_ctr - 0.5 * (hs - 1),\n",
    "                         x_ctr + 0.5 * (ws - 1),\n",
    "                         y_ctr + 0.5 * (hs - 1)))\n",
    "    print(ws)\n",
    "    return anchors\n",
    "\n",
    "def _ratio_enum(anchor, ratios):\n",
    "    \"\"\"\n",
    "    Enumerate a set of anchors for each aspect ratio wrt an anchor.\n",
    "    \"\"\"\n",
    "    #anchor [ 0  0 15 15], ratios [0.5, 1, 2]\n",
    "    w, h, x_ctr, y_ctr = _whctrs(anchor) # # 16 16 7.5 7.5\n",
    "    size = w * h # 256\n",
    "    size_ratios = size / ratios # [512. 256. 128.]\n",
    "    ws = np.round(np.sqrt(size_ratios)) # [23. 16. 11.]\n",
    "    hs = np.round(ws * ratios) # [12. 16. 22.]\n",
    "    anchors = _mkanchors(ws, hs, x_ctr, y_ctr)\n",
    "    \"\"\"\n",
    "    [[-3.5  2.  18.5 13. ]\n",
    "     [ 0.   0.  15.  15. ]\n",
    "     [ 2.5 -3.  12.5 18. ]]\n",
    "    \"\"\"\n",
    "    return anchors\n",
    "\n",
    "def _scale_enum(anchor, scales):\n",
    "    \"\"\"\n",
    "    Enumerate a set of anchors for each scale wrt an anchor.\n",
    "    \"\"\"\n",
    "\n",
    "    w, h, x_ctr, y_ctr = _whctrs(anchor)\n",
    "    ws = w * scales\n",
    "    hs = h * scales\n",
    "    anchors = _mkanchors(ws, hs, x_ctr, y_ctr)\n",
    "    return anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23.]\n",
      " [16.]\n",
      " [11.]]\n",
      "[[184.]\n",
      " [368.]\n",
      " [736.]]\n",
      "[[128.]\n",
      " [256.]\n",
      " [512.]]\n",
      "[[ 88.]\n",
      " [176.]\n",
      " [352.]]\n"
     ]
    }
   ],
   "source": [
    "anchors = generate_anchors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -84.,  -40.,   99.,   55.],\n",
       "       [-176.,  -88.,  191.,  103.],\n",
       "       [-360., -184.,  375.,  199.],\n",
       "       [ -56.,  -56.,   71.,   71.],\n",
       "       [-120., -120.,  135.,  135.],\n",
       "       [-248., -248.,  263.,  263.],\n",
       "       [ -36.,  -80.,   51.,   95.],\n",
       "       [ -80., -168.,   95.,  183.],\n",
       "       [-168., -344.,  183.,  359.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "529"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "23*23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
