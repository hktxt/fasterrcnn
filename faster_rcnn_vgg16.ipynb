{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import vgg16\n",
    "from utils.config import opt\n",
    "import import_ipynb\n",
    "from faster_rcnn import FasterRCNN\n",
    "from model.region_proposal_network import RegionProposalNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "caffe_pretrain = False # use caffe pretrained model instead of torchvision\n",
    "caffe_pretrain_path = 'checkpoints/vgg16_caffe.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decom_vgg16(): # see Dev/vgg16.ipynb\n",
    "    # https://github.com/chenyuntc/simple-faster-rcnn-pytorch/blob/0.4/model/faster_rcnn_vgg16.py#L12\n",
    "    # the 30th layer of features is relu of conv5_3\n",
    "    if opt.caffe_pretrain:\n",
    "        model = vgg16(pretrained=False)\n",
    "        if not opt.load_path:\n",
    "            model.load_state_dict(torch.load(opt.caffe_pretrain_path))\n",
    "    else:\n",
    "        model = vgg16(not opt.load_path)\n",
    "\n",
    "    features = list(model.features)[:30]\n",
    "    classifier = model.classifier\n",
    "\n",
    "    classifier = list(classifier)\n",
    "    del classifier[6]\n",
    "    if not opt.use_drop:\n",
    "        del classifier[5]\n",
    "        del classifier[2]\n",
    "    classifier = nn.Sequential(*classifier)\n",
    "\n",
    "    # freeze top4 conv\n",
    "    for layer in features[:10]:\n",
    "        for p in layer.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    return nn.Sequential(*features), classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FasterRCNNVGG16(FasterRCNN):\n",
    "    \"\"\"Faster R-CNN based on VGG-16.\n",
    "    For descriptions on the interface of this model, please refer to\n",
    "    :class:`model.faster_rcnn.FasterRCNN`.\n",
    "    Args:\n",
    "        n_fg_class (int): The number of classes excluding the background.\n",
    "        ratios (list of floats): This is ratios of width to height of\n",
    "            the anchors.\n",
    "        anchor_scales (list of numbers): This is areas of anchors.\n",
    "            Those areas will be the product of the square of an element in\n",
    "            :obj:`anchor_scales` and the original area of the reference\n",
    "            window.\n",
    "    \"\"\"\n",
    "\n",
    "    feat_stride = 16  # downsample 16x for output of conv5 in vgg16\n",
    "\n",
    "    def __init__(self,\n",
    "                 n_fg_class=20,\n",
    "                 ratios=[0.5, 1, 2],\n",
    "                 anchor_scales=[8, 16, 32]\n",
    "                 ):\n",
    "                 \n",
    "        extractor, classifier = decom_vgg16()\n",
    "\n",
    "        rpn = RegionProposalNetwork(\n",
    "            512, 512,\n",
    "            ratios=ratios,\n",
    "            anchor_scales=anchor_scales,\n",
    "            feat_stride=self.feat_stride,\n",
    "        )# see Dev/net.ipynb\n",
    "\n",
    "        head = VGG16RoIHead(\n",
    "            n_class=n_fg_class + 1,\n",
    "            roi_size=7,\n",
    "            spatial_scale=(1. / self.feat_stride),\n",
    "            classifier=classifier\n",
    "        )\n",
    "\n",
    "        super(FasterRCNNVGG16, self).__init__(\n",
    "            extractor,\n",
    "            rpn,\n",
    "            head,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16RoIHead(nn.Module):\n",
    "    \"\"\"Faster R-CNN Head for VGG-16 based implementation.\n",
    "    This class is used as a head for Faster R-CNN.\n",
    "    This outputs class-wise localizations and classification based on feature\n",
    "    maps in the given RoIs.\n",
    "    \n",
    "    Args:\n",
    "        n_class (int): The number of classes possibly including the background.\n",
    "        roi_size (int): Height and width of the feature maps after RoI-pooling.\n",
    "        spatial_scale (float): Scale of the roi is resized.\n",
    "        classifier (nn.Module): Two layer Linear ported from vgg16\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_class, roi_size, spatial_scale,\n",
    "                 classifier):\n",
    "        # n_class includes the background\n",
    "        super(VGG16RoIHead, self).__init__()\n",
    "\n",
    "        self.classifier = classifier\n",
    "        self.cls_loc = nn.Linear(4096, n_class * 4)\n",
    "        self.score = nn.Linear(4096, n_class)\n",
    "\n",
    "        normal_init(self.cls_loc, 0, 0.001)\n",
    "        normal_init(self.score, 0, 0.01)\n",
    "\n",
    "        self.n_class = n_class\n",
    "        self.roi_size = roi_size\n",
    "        self.spatial_scale = spatial_scale\n",
    "        self.roi = RoIPooling2D(self.roi_size, self.roi_size, self.spatial_scale)\n",
    "\n",
    "    def forward(self, x, rois, roi_indices):\n",
    "        \"\"\"Forward the chain.\n",
    "        We assume that there are :math:`N` batches.\n",
    "        Args:\n",
    "            x (Variable): 4D image variable.\n",
    "            rois (Tensor): A bounding box array containing coordinates of\n",
    "                proposal boxes.  This is a concatenation of bounding box\n",
    "                arrays from multiple images in the batch.\n",
    "                Its shape is :math:`(R', 4)`. Given :math:`R_i` proposed\n",
    "                RoIs from the :math:`i` th image,\n",
    "                :math:`R' = \\\\sum _{i=1} ^ N R_i`.\n",
    "            roi_indices (Tensor): An array containing indices of images to\n",
    "                which bounding boxes correspond to. Its shape is :math:`(R',)`.\n",
    "        \"\"\"\n",
    "        # in case roi_indices is  ndarray\n",
    "        roi_indices = at.totensor(roi_indices).float()\n",
    "        rois = at.totensor(rois).float()\n",
    "        indices_and_rois = t.cat([roi_indices[:, None], rois], dim=1)\n",
    "        # NOTE: important: yx->xy\n",
    "        xy_indices_and_rois = indices_and_rois[:, [0, 2, 1, 4, 3]]\n",
    "        indices_and_rois =  xy_indices_and_rois.contiguous()\n",
    "\n",
    "        pool = self.roi(x, indices_and_rois)\n",
    "        pool = pool.view(pool.size(0), -1)\n",
    "        fc7 = self.classifier(pool)\n",
    "        roi_cls_locs = self.cls_loc(fc7)\n",
    "        roi_scores = self.score(fc7)\n",
    "        return roi_cls_locs, roi_scores\n",
    "\n",
    "\n",
    "def normal_init(m, mean, stddev, truncated=False):\n",
    "    \"\"\"\n",
    "    weight initalizer: truncated normal and random normal.\n",
    "    \"\"\"\n",
    "    # x is a parameter\n",
    "    if truncated:\n",
    "        m.weight.data.normal_().fmod_(2).mul_(stddev).add_(mean)  # not a perfect approximation\n",
    "    else:\n",
    "        m.weight.data.normal_(mean, stddev)\n",
    "        m.bias.data.zero_()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
